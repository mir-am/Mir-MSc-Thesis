\chapter{کلیات}
\section{مقدمه}

ماشین بردار پشتیبان\footnote{\lr{Support Vector Machine (SVM)}} توسط وپنیک\footnote{\lr{Vapnik}} و کورتس\footnote{\lr{Cortes}} در سال 1995 ارائه شد \cite{vapnik1995}. این روش یادگیری با نظارت بر پایه کمینه کردن ریسک ساختاری\footnote{\lr{Structural Risk}} طراحی شده است \cite{vapnik1998}. ایده اصلی \lr{SVM} پیدا کردن یک ابرصفحه با بیشترین فاصله ممکن از داده‌های دو کلاس می‌باشد. بطوریکه یک مسئله  بهینه‌سازی از نوع برنامه‌ریزی درجه دو\footnote{\lr{Quadratic Programming Problem (QPP)}} برای بدست آوردن چنین ابرصفحه‌ای حل می‌شود این روش یادگیری در مسائل مختلف مانند تشخیص آریتمی‌های قلبی \cite{nasiri2009}، شناسایی نفوذ به شبکه‌های کامپیوتری \cite{raman2017}، دسته‌بندی متن\cite{lee2012} و شناسایی هرزنامه \cite{zoubi2018} مورد استفاده قرار گرفته است.

در دو دهه گذشته، پژوهشگران دسته‌بندهایی مبتنی بر روش ماشین بردار پشتیبان ارائه کرده‌اند \cite{nayak2015}. در سال 2001، ماشین بردار پشتیبان مبتنی بر مفهوم نزدیکی\footnote{\lr{Proximal Support Vector Machine (PSVM)}}  (\lr{PSVM}) ارائه شد \cite{mang2001}. در این روش دو ابرصفحه موازی برای دسته‌بندی نمونه‌ها ایجاد می‌شود. در سال 2002، ماشین بردار پشتیبان فازی\footnote{\lr{Fuzzy Support Vector Machine (FSVM)}}  (\lr{FSVM}) \cite{lin2002} ارائه گردید. در این روش به هر یک از نمونه‌های هر دو کلاس، تعلق فازی داده می‌شود. بطوریکه اثر نمونه‌های نویزی و پرت در ایجاد مدل خروجی کم خواهد شد. در سال 2006، ماشین بردار پشتیبان با رویکرد مقدار ویژه تعمیم یافته\footnote{\lr{Generalized Eigenvalue Proximal Support Vector Machine (GEPSVM)}}  (\lr{GEPSVM}) ارائه شد \cite{mang2006}. برخلاف روش \lr{PSVM}، این روش دو ابرصفحه غیر موازی ایجاد می‌کند که هر یک از این ابرصفحه‌ها به نمونه‌های کلاس خود نزدیک است و از نمونه‌های کلاس مقابل تا جای ممکن فاصله می‌گیرد. همچنین روش \lr{PSVM} بر روی مسئله \lr{XOR} عملکرد بهتری نسبت به روش \lr{SVM} اصلی دارد.

در سال 2007، ماشین بردار پشتیبان دو قلو\footnote{\lr{Twin Support Vector Machine (TSVM)}}  (\lr{TSVM}) با هدف بهبود پیچیدگی زمانی \lr{SVM} ارائه گردید \cite{jayadeva2007}. ایده اصلی این روش یادگیری، بدست آوردن دو ابرصفحه غیر موازی است. بطوریکه هر ابرصفحه غیر موازی به نمونه‌های کلاس خود نزدیک است و نمونه‌های کلاس مقابل دور می‌شود. دو مسئله بهینه‌سازی کوچک از نوع برنامه‌ریزی درجه دو برای بدست آوردن این دو ابرصفحه غیر موازی حل می‌گردد. در حالی‌که در روش \lr{SVM} یک مسئله بهینه‌سازی بزرگ حل می‌شود. در نتیجه، روش ماشین بردار پشتیبان دو قلو در تئوری 4 برابر سریعتر از روش \lr{SVM} است.

در دهه اخیر، دسته‌بندهای مختلفی بر مبنای روش ماشین بردار پشتیبان دو قلو ارائه شده است \cite{ding2017,huang2018}. در سال 2009، ماشین بردار پشتیبان دو قلو کمترین مربعات\footnote{\lr{Least Squares Twin Support Vector Machine (LS-TSVM)}}  (\lr{LS-TSVM}) معرفی شد \cite{kumar2009}. در این روش، دو دستگاه معادلات خطی به جای دو مسئله بهینه‌سازی درجه دو حل می‌شود. در نتیجه، سرعت یادگیری روش \lr{LS-TSVM} به طور قابل توجه‌ای بیشتر از روش \lr{TSVM} اصلی بر روی مجموعه داده‌های بزرگ می‌باشد. در سال 2012، ماشین بردار پشتیبان دو قلو وزن دار با اطلاعات محلی\footnote{\lr{Weighted Twin Support Vector Machine with Local Information (WLTSVM)}}  (\lr{WLTSVM}) ارائه شد \cite{ye2012}. برخلاف \lr{TSVM} اصلی، این روش شباهت و اهمیت نمونه‌ها را با ساخت گراف نزدیک‌ترین همسایه در نظر می‌گیرد. بطوریکه، به هر یک از نمونه‌ها بر اساس تعداد همسایه‌های نزدیک به آن وزن نسبت داده می‌شود و همچنین نمونه‌های حاشیه در ایجاد دو ابرصفحه غیر موازی اهمیت ویژه‌ای خواهند داشت. در حالی‌که در روش \lr{TSVM} اصلی، تمام نمونه‌ها در ایجاد ابرصفحه غیرموازی نقش دارند.

در سال 2013، ماشین بردار پشتیبان دو قلو ساختاری\footnote{\lr{Structural Twin Support Vector Machine (STSVM)}}  (\lr{STSVM}) ارائه گردید \cite{qi2013}.  این روش یادگیری اطلاعات مفید ساختاری درون هر کلاس و توزیع نمونه‌ها را از طریق خوشه‌بندی سلسله مراتبی در مدل خروجی لحاظ می‌کند.  در سال 2015، ماشین بردار پشتیبان دو قلو ساختاری با رویکرد گراف نزدیک‌ترین همسایه (\lr{KNN-STSVM}) معرفی شد \cite{pan2015}. در این روش، علاوه بر در نظر گرفتن اطلاعات ساختاری نمونه‌ها، با استفاده از گراف نزدیک‌ترین همسایه به نمونه‌ها وزن داده می‌شود. در نتیجه، دقت دسته‌بند مدل خروجی افزایش می‌یابد.

\section{تعریف مسئله} 
اگرچه ماشین بردار پشتیبان دو قلو نسبت به \lr{SVM} اصلی سریعتر است و داده‌های نامتوزان را بهتر دسته‌بندی می‌کند. با این حال، این روش یادگیری نقاظ ضعفی نیز دارد که عبارتند از:
\begin{enumerate}
	\item 	در این روش، دو مسئله بهنیه‌سازی از نوع برنامه‌ریزی درجه دو باید حل گردد. چناچه نمونه‌های آموزشی بسیار زیاد باشد، سرعت یادگیری این روش به شدت کند می‌شود. زیرا مرتبه زمانی حل کردن یک مسئله بهینه‌سازی درجه دو برابر با $\mathcal{O}(n^3)$ است. بطوریکه $n$ نشان دهنده تعداد نمونه‌های آموزشی می‌باشد. برای رفع کردن این مشکل، از روش کمترین مربعات  \cite{kumar2009} استفاده می‌گردد. در نتیجه دو دستگاه معادلات خطی به جای دو مسئله بهینه‌سازی درجه دو حل می‌شود. بنابراین سرعت آموزش دسته‌بند بر روی مجموعه داده‌های بزرگ به طور قابل توجه‌ای افزایش می‌یابد.
	\item برخلاف روش \lr{SVM} اصلی، ماشین بردار پشتیبان دو قلو ریسک تجربی\footnote{\lr{Empirical Risk}} را در مسئله بهینه‌سازی خود کمینه می‌کند .\cite{shao2011} این مسئله، موجب پدیده برازش بیش از حد\footnote{\lr{Overfitting}} می‌شود. به عبارت دیگر، مدل خروجی تمام نمونه‌های آموزشی را به خوبی دسته‌بندی می‌کند. بطوریکه دقت مدل خروجی روی نمونه‌های تست کاهش می‌یابد. این مشکل، قدرت تعمیم‌پذیری\footnote{\lr{Generalization}} روش ماشین بردار پشتیبان دو قلو را کم می‌کند. برای برطرف کردن این مشکل، در سال 2011، شائو و همکاران، ماشین بردار پشتیبان دو قلو مبتنی بر مرز\footnote{\lr{Twin Bounded Support Vector Machine (TBSVM)}}  (\lr{TBSVM}) را ارائه کردند \cite{shao2011}. این روش، به مسئله بهینه‌سازی روش \lr{TSVM} اصلی، یک جمله رگولارسیون اضافه می‌کند تا مانند روش \lr{SVM} اصلی حاشیه بیشینه گردد.
	\item ماشین بردار پشتیبان دو قلو به تمام نمونه‌های آموزشی اهمیت یکسانی می‌دهد. در نتیجه ابرصفحه غیر موازی به نمونه‌های نویزی و پرت نیز نزدیک می‌شود. بنابراین دقت و تعمیم‌پذیری مدل ایجاد شده روی نمونه‌های تست کاهش می‌یابد. ایده اصلی این تحقیق، حل کردن این مسئله است. در پژوهش‌های پیشین نیز به این مسئله پرداخته شده است. روش \lr{WLTSVM} \cite{ye2012} با ایجاد گراف نزدیک‌ترین همسایه، به نمونه‌های آموزشی وزن نسبت می‌دهد تا اثر نویز و نمونه‌های پرت در ایجاد مدل برای دسته‌بندی کاهش یابد.
\end{enumerate}

\section{نوآوری‌های پژوهش}
ایده اصلی این پژوهش بر گرفته از روش یادگیری \lr{WLTSVM}  \cite{ye2012} است و نقاط ضعف این دسته‌بند را حل می‌کند. نوآوری‌های این تحقیق به طور خلاصه عبارتند از:

\begin{enumerate}
	\item 	در روش \lr{WLTSVM} مانند روش \lr{TSVM} اصلی دو مسئله بهینه‌سازی از نوع برنامه‌ریزی درجه دو حل می‌گردد. همچنین در روش \lr{WLTSVM}، باید گراف نزدیک‌ترین همسایه بدست آید تا بتوان وزن تمام نمونه‌های آموزشی را محاسبه کرد. مرتبه زمانی ایجاد این گراف و ماتریس وزن برابر با $\mathcal{O}(n^{2}logn)$ است. در نتیجه، فرآیند یادگیری روش  \lr{WLTSVM}برای مجموعه داده‌های بزرگ کند و زمان‌بر است. جهت بهبود فرآیند یادگیری، روش ماشین بردار پیشتیبان دو قلو کمترین مربعات مبتنی بر نزدیک‌ترین همسایه\footnote{\lr{KNN-based Least Squares Twin Support Vector Machine (KNN-LSTSVM)}}  (\lr{KNN-LSTSVM}) معرفی شده است \cite{mir2018}. این روش علاوه بر داشتن مزایای روش \lr{WLTSVM} مانند وزن‌دهی به نمونه‌ها جهت کاهش اثر نمونه های نویزی و پرت، همچنین دو دستگاه معادلات خطی به جای دو مسئله بهینه‌سازی درجه دو حل می‌شود. در نتیجه، سرعت آموزش روش پیشنهادی به طور قابل توجه‌ای بیشتر از روش \lr{WLTSVM} است و پیاده‌سازی آن نیز ساده‌تر می‌باشد. زیرا روش \lr{KNN-LSTSVM} همانند روش  \lr{LSTSVM} نیاز به الگوریتم‌های حل مسائل بهینه‌سازی ندارد.
	\item با وجود اینکه روش \lr{WLTSVM} با استفاده از گراف نزدیک‌ترین همسایه، به نمونه‌های آموزشی وزن می‌دهد، روش وزن‌دهی صرفا بر اساس شمارش تعداد همسایه‌های یک نمونه از طریق گراف نزدیک‌ترین همسایه است.  جهت بهبود شیوه وزن‌دهی به نمونه‌ها، روش ماشین بردار پشتیبان دو قلو مبتنی بر رگولارسیون و نزدیک‌ترین همسایه\footnote{\lr{A Regularized KNN-based Twin Support Vector Machine (RKNN-TSVM)}}  (\lr{RKNN-TSVM}) ارائه شده است. روش پیشنهادی، به یک نمونه آموزشی بر اساس فاصله آن نمونه با همسایه‌های خود وزن می‌دهد. مزیت این روش وزن‌دهی این است که نمونه‌های با چگالی بالا\footnote{\lr{High-density samples}} بهتر از نمونه‌های نویزی و پرت تفکیک و شناسایی می‌شود. همچنین به نمونه‌هایی که همسایه‌شان نزدیک‌تر است، وزن بیشتری نسبت داده می‌شود.
	\item روش پیشنهادی (\lr{RKNN-TSVM}) برخلاف روش \lr{WLTSVM} و \lr{TSVM} اصلی، ریسک ساختاری را کمینه می‌کند. بدین منظور یک جمله رگولارسیون به مسئله بهینه‌سازی روش پیشنهادی اضافه شده است. هدف مانند \lr{SVM} اصلی، بیشینه کردن مرز یا حاشیه است. در مجموع، مدل خروجی دچار پدیده برازش بیش از حد نمی‌شود و از تعمیم‌پذیری بهتری برخوردار است.
	\item	روش \lr{WLTSVM} برای ساخت گراف نزدیک‌ترین همسایه از الگوریتم جستجوی کامل\footnote{\lr{Full Search Algorithm (FSA)}}  (\lr{FSA}) استفاده می‌کند که مرتبه زمانی آن برابر با $\mathcal{O}(n^{2})$ است. با این حال روش پیشنهادی (\lr{RKNN-TSVM}) از الگوریتم نزدیک‌ترین همسایه مبتنی بر تفاوت مکانی فاصله‌ها\footnote{\lr{Location difference of multiple distances based k-nearest neighbors algorithm (LDMDBA)}}  (\lr{LDMDBA}) بهره می‌برد \cite{xia2015}. مرتبه زمانی این الگوریتم برابر با$\mathcal{O}(log d n log n)$  می‌باشد که از الگوریتم \lr{FSA} کمتر است. همچنین الگوریتم \lr{LDMDBA} برای نسخه غیرخطی روش پیشنهادی موثرتر است. زیرا پیدا کردن نزدیک‌ترین همسایه‌های یک نمونه در فضای ویژگی با ابعاد بالا با این الگوریتم سریع‌تر از روش \lr{FSA} می‌باشد.
\end{enumerate}

\newpage
