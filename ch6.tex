% Conclusion

\chapter{نتیجه‌گیری و پژوهش‌های آینده}\label{ch:6}

\section{مقدمه}\label{sec:6:1}
در این فصل، ابتدا ویژگی‌های دسته‌بندهای پیشنهادی مرور می‌شود. سپس یافته‌های مهم این پژوهش به طور خلاصه بیان می‌شود. در آخر، پیشنهاد هایی برای پژوهش‌های آینده بیان می‌گردد.

\section{مروری بر دسته‌بندهای پیشنهادی}\label{sec:6:2}
هدف اصلی این پژوهش، ارائه یک دسته‌بند مبتنی بر ماشین بردار پشتیبان دو قلو است که بتواند دقت و تعمیم‌پذیری مطلوبی در برابر داده‌های نویزی و پرت داشته باشد. بدین منظور دو دسته‌بند \lr{KNN-LSTSVM} و \lr{RKNN-TSVM} به ترتیب در فصول \ref{ch:3} و \ref{ch:4} ارائه شد.

دسته‌بند \lr{KNN-LSTSVM} \cite{mir2018} با ایده گرفتن از روش \lr{WLTSVM} گراف نزدیک‌ترین همسایه را برای تمام نمونه‌های آموزشی ایجاد می‌کند. سپس با استفاده از گراف درون کلاسی $W_{w}$ به نمونه‌ها بر اساس شماری تعداد همسایه‌های نزدیک‌شان وزن می‌دهد و همچنین با بکارگیری گراف برون کلاسی $W_{b}$، نمونه‌های حاشیه‌ای هر کلاس را مشخص می‌کند. بطوریکه دقت و تعمیم‌پذیری روش \lr{KNN-LSTSVM} نسبت به روش \lr{TSVM} با وجود داده‌های نویزی بهتر است. به منظور افزایش سرعت یادگیری و آموزش، روش \lr{KNN-LSTSVM} همانند روش \lr{LSTSVM} قید مسئله بهینه‌سازی را در تابع هدف جایگذاری می‌کند. بطوریکه مدل خروجی با حل کردن دو دستگاه معادلات خطی بدست می‌آید. دسته‌بند پیشنهادی در بخش \ref{sec:5:2} مورد ارزیابی و بررسی قرار گرفت. نتایج نشان می‌دهد که روش پیشنهادی نسبت به روش \lr{TSVM} از نظر دقت دسته‌بندی و سرعت یادگیری به طور قابل توجه‌ای بهتر می‌باشد.

در ادامه، دسته‌بند \lr{RKNN-TSVM} با هدف برطرف کردن مشکلات روش \lr{WLTSVM} ارائه شده است. روش پیشنهادی  سه مزیت نسبت به روش  \lr{WLTSVM} دارد که عبارتند از:
\begin{enumerate}
	\item روش پیشنهادی به نمونه‌ها بر اساس فاصله از نزدیک‌ترین همسایه‌شان وزن می‌دهد. برای مثال، اگر  فاصله نزدیکترین همسایه‌های یک نمونه از آن بسیار کم باشد، وزن بیشتری به این نمونه نسبت داده می‌شود. این شیوه وزن‌دهی نمونه‌های پرتراکم را بهتر  از روش  \lr{WLTSVM}شناسایی می‌کند.
	\item روش پیشنهادی \lr{RKNN-TSVM} برخلاف روش \lr{WLTSVM} ریسک ساختاری را کمینه می‌کند. زیرا جمله رگولارسیون به مسائل بهینه‌سازی روش پیشنهادی اضافه شده است. بطوریکه مانند روش  \lr{SVM} حاشیه بیشینه می‌گردد. کمینه کردن ریسک ساختاری در روش پیشنهادی باعث بهبود تعمیم‌پذیری آن شده است.
	\item سرعت یادگیری روش  \lr{WLTSVM}به دلیل محاسبه گراف نزدیک‌ترین همسایه برای مجموعه داده‌های بزرگ بسیار کاهش می‌یابد. با  این حال روش پیشنهادی از الگوریتم \lr{LDMDBA} برای ساخت گراف نزدیک‌ترین همسایه استفاده می‌کند. مرتبه زمانی این الگوریتم برابر با   $\mathcal{O}(\log nm\log m)$ است. بطوریکه سرعت یادگیری روش پیشنهادی نسبت به روش \lr{WLTSVM} برای مجموعه داده‌های بزرگ به طور قابل    توجه‌ای سریعتر است. 
\end{enumerate} 

نتایج بدست آمده در بخش \ref{sec:5:3}، مزیت‌های دسته‌بند \lr{RKNN-TSVM} نسبت به روش \lr{WLTSVM} را تایید می‌کند.

\section{مروری بر یافته‌های این پژوهش}\label{sec:6:3}
در فصل \ref{ch:5}، دو دسته‌بند پیشنهادی یعنی \lr{KNN-LSTSVM} و \lr{RKNN-TSVM} به طور جامع بررسی و ارزیابی شده است. در این بخش یافته‌های مهم و اصلی این پژوهش براساس نتایج ارزیابی به طور خلاصه در زیر بیان شده است.
\begin{itemize}[label=$\bullet$]
	\item روش‌های  \lr{KNN-LSTSVM} و  \lr{WLTSVM} با در نظر گرفتن گراف درون کلاسی در مسئله بهینه‌سازی‌شان به نمونه‌های آموزشی وزن می‌دهند. بطوریکه مدل خروجی نسبت به نمونه‌های پرت و نویزی حساسیت کمتری خواهد داشت. در نتیجه دقت و تعمیم‌پذیری مدل خروجی افزایش می‌یابد.
	\item روش‌های  \lr{LSTSVM} و  \lr{KNN-LSTSVM} با استفاده از تکنیک کمترین مربعات، قید مسئله بهینه‌سازی را در تابع هدف جایگذاری می‌کنند. بدین ترتیب مدل خروجی با حل کردن دو دستگاه معادلات خطی بدست می‌آید. فرآیند یادگیری در این گونه روش‌ها برای مجموعه داده‌های بزرگ بسیار سریع است.
	\item روش‌های \lr{WLTSVM} و  \lr{RKNN-TSVM} با در نظر گرفتن گراف برون کلاسی در مسائل بهینه‌سازی‌شان، نمونه‌های حاشیه‌ای هر کلاس را مشخص می‌کنند. بطوریکه ابرصفحه به جای تمام نمونه‌های کلاس مقابل، فقط از نمونه‌های حاشیها‌‌‌ی کلاس مقابل حداکثر فاصله ممکن را می‌گیرد. در نتیجه ابعاد مسئله بهینه‌سازی دوگان کوچکتر می‌شود. در نتیجه مرتبه زمانی دسته‌بند بهبود می‌یابد.
	\item روش پیشنهادی  \lr{RKNN-TSVM} همانند روش  \lr{TBSVM} ریسک ساختاری را کمینه می‌کند. بطوریکه مسائل بهینه‌سازی در این  روش‌ها مثبت معین است و از شرایط ماتریس منفرد جلوگیری شده است. با این حال کمینه کردن ریسک ساختاری منجر به معرفی یک پارامتر جدید به دسته‌بند می‌شود. از طرفی تنظیم کردن این پارامتر تعمیم‌پذیری مدل خروجی را بهبود داده است. از طرف دیگر، معرفی این پارامتر باعث افزایش بار محاسباتی جستجوی پارامترهای بهینه می‌شود. 
	\item روش  \lr{WLTSVM} براساس شمارش تعداد همسایه‌های نزدیک به یک نمونه وزن می‌دهد. در حالی‌که روش پیشنهادی  \lr{RKNN-TSVM} به یک نمونه براساس فاصله بین آن نمونه و نزدیک‌ترین همسایه‌هایش وزن می‌دهد. بطوریکه ماتریس وزن شامل اعداد بین بازه   $\left[0,1\right]$ است. این نوع شیوه وزن‌دهی باعث شناسایی بهتر نمونه‌های پرتراکم در فضای ویژگی می‌شود و همچنین نمونه‌های پرت و نویزی بهتر از روش \lr{WLTSVM} مشخص می‌شوند. نتایج نشان داده است که این نوع شیوه وزن‌دهی دقت دسته‌بند  را بهبود می‌دهد.
\end{itemize}

